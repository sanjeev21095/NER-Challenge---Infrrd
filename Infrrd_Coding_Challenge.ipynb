{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rw-XTRg7Fas5"
   },
   "source": [
    "# NER Coding Challenge\n",
    "### In any text document, there are particular terms that represent specific entities that are more informative and have a unique context. These entities are known as named entities , which more specifically refer to terms that represent real-world objects like people, places, organizations, and so on, which are often denoted by proper names. A naive approach could be to find these by looking at the noun phrases in text documents. Named entity recognition (NER) , also known as entity chunking/extraction , is a popular technique used in information extraction to identify and segment the named entities and classify or categorize them under various predefined classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfgs0OS2Cj_8"
   },
   "source": [
    "# Overview of what has been implemented\n",
    "\n",
    "*   Data Exploration\n",
    "*   Simple classifiers - Perceptron, SGD Classifier, Multinomial Naive bayes\n",
    "*   Character based LSTM\n",
    "*   ELMO based residual LSTM\n",
    "*   Bonus question - Confidence score for predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydoI0eA8GAh3"
   },
   "source": [
    "## 1 - Load the given training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ypBodn_GFhJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"train.txt\", sep=\"\\t\", header=None,names=[\"Name\", \"Tag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFd8J_ndGQqG"
   },
   "source": [
    "## 1.1 - Understand what's there in the data - Exploratory Data Analysis\n",
    " First, the data is loaded into a Pandas DataFrame. This can be done easily using the read_csv function, specifying that the separator is a tab space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "uBXiLJJeGSln",
    "outputId": "215b0acb-8ed5-4d29-c715-3572666ec184"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>view</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Tag\n",
       "0  @paulwalk   O\n",
       "1         It   O\n",
       "2         's   O\n",
       "3        the   O\n",
       "4       view   O"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0zD4FzgGWzb"
   },
   "source": [
    "### Are there any NaN rows? If yes, remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2YI_oadBGZlu",
    "outputId": "6c10cb4f-ae9f-45ac-92b5-081efd6c0c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nan rows is 2168\n"
     ]
    }
   ],
   "source": [
    "nan_rows = train_data[train_data['Name'].isnull()]\n",
    "print(\"Number of Nan rows is %d\" %(len(nan_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_2MO9cgNGbz3",
    "outputId": "1ee20505-aead-4e30-c62b-0e9088ed1c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New training data length is 55725\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna()\n",
    "print(\"New training data length is %d\" %(len(train_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIgChcsBGiKa"
   },
   "source": [
    "### What are the entity tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "EJijl5DjGpkJ",
    "outputId": "99ca3a04-2ca4-4b4e-ac1a-11ff16003896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['O', 52997], ['B-person', 566], ['B-location', 494], ['I-person', 288], ['B-group', 230], ['I-location', 226], ['B-corporation', 196], ['I-product', 163], ['I-creative-work', 150], ['I-group', 132], ['B-product', 130], ['B-creative-work', 110], ['I-corporation', 43]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAFLCAYAAAAXhLEeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKgtSSQiImpLEomIiNqSRCIiorb/D7keulSu5SwJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_list = train_data.Tag.value_counts().reset_index().values.tolist()\n",
    "print(tags_list)\n",
    "import matplotlib.pyplot as plt\n",
    "tag_vals = [i[0] for i in tags_list]\n",
    "counts = [i[1] for i in tags_list]\n",
    "plt.bar(range(0,len(tag_vals)),counts)\n",
    "plt.xticks(range(0,len(tag_vals)), tag_vals, rotation='vertical')\n",
    "plt.xlabel(\"Tags\")\n",
    "plt.ylabel(\"Counts of tags\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJckGFXuGtot"
   },
   "source": [
    "We see that the tags are in \"BIO\" format. BIO stands for Beginning, Inside and Outside (of a text segment). In a system that recognizes entity boundaries only, only three labels are used: B, I and O. What is also understood from the above output is that the tags are not evenly distributed. Since the class 'O' is more than the rest, we shall neglect it and make use of the remaining tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "mTX2PdmOGxDy",
    "outputId": "283ddeff-6bc5-4a9e-d91f-44e27a567b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['B-person', 566], ['B-location', 494], ['I-person', 288], ['B-group', 230], ['I-location', 226], ['B-corporation', 196], ['I-product', 163], ['I-creative-work', 150], ['I-group', 132], ['B-product', 130], ['B-creative-work', 110], ['I-corporation', 43]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAFLCAYAAAA5wZCMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSEiImpJChERUUtSiIiI2v8H3mcWbdjj+WIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_list.pop(0)\n",
    "print(tags_list)\n",
    "tag_vals = [i[0] for i in tags_list]\n",
    "counts = [i[1] for i in tags_list]\n",
    "plt.bar(range(0,len(tag_vals)),counts)\n",
    "plt.xticks(range(0,len(tag_vals)), tag_vals, rotation='vertical')\n",
    "plt.xlabel(\"Tags\")\n",
    "plt.ylabel(\"Counts of tags\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jwxbi5uZG0VF"
   },
   "source": [
    "### What else is present in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBTgzaSGG5Vv"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, defaultdict\n",
    "Tag = namedtuple(\"Tag\", [\"token\", \"tag\"])\n",
    "def load_sequences(filename, sep=\"\\t\", notypes=False):\n",
    "    tag_count = defaultdict(int)\n",
    "    sequences = []\n",
    "    with open(filename) as fp:\n",
    "        seq = []\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                line = line.split(sep)\n",
    "                if notypes:\n",
    "                    line[1] = line[1][0]\n",
    "                tag_count[line[1]] += 1\n",
    "                #print line\n",
    "                seq.append(Tag(*line))\n",
    "            else:\n",
    "                sequences.append(seq)\n",
    "                seq = []\n",
    "        if seq:\n",
    "            sequences.append(seq)\n",
    "    return sequences, tag_count\n",
    "sequences, tag_count = load_sequences(\"train.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2t1dT7O7HR9C"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "URL_REGEX = re.compile(r'^http[s]?://')\n",
    "assert URL_REGEX.match(\"http://Google.com\") is not None\n",
    "assert URL_REGEX.match(\"https://Google.com\") is not None\n",
    "assert URL_REGEX.match(\"abchttps://Google.com\") is None\n",
    "REPEATED_CHAR_REGEX=re.compile(r'^[\\.\\,!\\?\"\\':;_\\-]{2,}$')\n",
    "assert REPEATED_CHAR_REGEX.match(\"!\") is None\n",
    "assert REPEATED_CHAR_REGEX.match(\"!!\") is not None\n",
    "assert REPEATED_CHAR_REGEX.match(\"!?...!\") is not None\n",
    "assert REPEATED_CHAR_REGEX.match('\".') is not None\n",
    "assert REPEATED_CHAR_REGEX.match(\"aaaaa\") is None\n",
    "assert REPEATED_CHAR_REGEX.match('\\\".') is not None\n",
    "WORD_REGEX=re.compile(r'^([A-Za-z]+[\\'\\-\\.]?)+$')\n",
    "assert WORD_REGEX.match(\"ABC\") is not None\n",
    "assert WORD_REGEX.match(\"ABC-D\") is not None\n",
    "assert WORD_REGEX.match(\"ABC'D\") is not None\n",
    "assert WORD_REGEX.match(\"ABC.DFC.\") is not None\n",
    "assert WORD_REGEX.match(\"9-1\") is None\n",
    "assert WORD_REGEX.match(\"A.B.C\") is not None\n",
    "NUMBER_REGEX=re.compile(r'^(([0-9]*[.]?[0-9]+)|([0-9]+[,]?[0-9]+))$')\n",
    "assert NUMBER_REGEX.match(\"123\") is not None\n",
    "assert NUMBER_REGEX.match(\"123,4\") is not None\n",
    "assert NUMBER_REGEX.match(\"12.5\") is not None\n",
    "assert NUMBER_REGEX.match(\".5\") is not None\n",
    "assert NUMBER_REGEX.match(\"12-A\") is None\n",
    "assert NUMBER_REGEX.match(\",55\") is None\n",
    "assert NUMBER_REGEX.match(\"5.5.55\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "JgLyMgxmHT_3",
    "outputId": "8d147abd-88bc-44c2-ee28-706b3dd6a6dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Words</td>\n",
       "      <td>48016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>8036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mentions (@___)</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Repeated characters (...)</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numbers</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>URLs</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hashtags</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alphanumeric characters</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Money ($$)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Type  Counts\n",
       "0                      Words   48016\n",
       "1                      Other    8036\n",
       "2            Mentions (@___)    1961\n",
       "3  Repeated characters (...)    1229\n",
       "4                    Numbers    1218\n",
       "5                       URLs     955\n",
       "6                   Hashtags     826\n",
       "7    Alphanumeric characters     459\n",
       "8                 Money ($$)      30"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token_type(t):\n",
    "    if len(t.token) > 1 and t.token[0] in ['\\'', '\\\"', '(', '-']:\n",
    "        return get_token_type(Tag(t.token[1:], t.tag))\n",
    "    if len(t.token) > 1 and t.token[0] == \"@\":\n",
    "        return \"Mentions (@___)\"\n",
    "    if len(t.token) > 1 and t.token[0] == \"#\":\n",
    "        return \"Hashtags\"\n",
    "    if len(t.token) > 1 and t.token[0] == \"$\":\n",
    "        return \"Money ($$)\"\n",
    "    if URL_REGEX.match(t.token):\n",
    "        return \"URLs\"\n",
    "    if NUMBER_REGEX.match(t.token):\n",
    "        return \"Numbers\"\n",
    "    if WORD_REGEX.match(t.token):\n",
    "        return \"Words\"\n",
    "    if t.token.isalnum():\n",
    "        return \"Alphanumeric characters\"\n",
    "    if REPEATED_CHAR_REGEX.match(t.token):\n",
    "        return \"Repeated characters (...)\"\n",
    "    return \"Other\"\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "pd.DataFrame(Counter(get_token_type(t) for seq in sequences for t in seq).most_common(), columns=[\"Type\", \"Counts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "es7O9dk3HebY"
   },
   "source": [
    "## 2 - Using basic algorithms like Perceptron, SGD classifier, Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYLe1eaaHixi"
   },
   "source": [
    "### Transform the given data into operable form using DictVectorizer. Use a 67-33 split to generate a dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "7nbLqRntHhBG",
    "outputId": "25da558c-f8af-480c-b89a-d814ed6fa10c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37335, 13794) (37335,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = train_data.drop('Tag', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(X.to_dict('records'))\n",
    "y = train_data.Tag.values\n",
    "\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS-ifNT7Hqqj"
   },
   "source": [
    "#### Load the libraries for the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e9Xl_uqHscQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SglypZNwHwHT"
   },
   "source": [
    "### 2.1 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "colab_type": "code",
    "id": "j_HBN87eHykH",
    "outputId": "09686abe-197a-4b90-b8bd-8aca1ea6d69b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "\n",
      "Norm: 14.80, NNZs: 170, Bias: -1.000000, T: 37335, Avg. loss: 0.002437\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 10.15, NNZs: 94, Bias: -1.000000, T: 37335, Avg. loss: 0.002330\n",
      "Total training time: 1.38 seconds.\n",
      "Norm: 17.06, NNZs: 259, Bias: -1.000000, T: 37335, Avg. loss: 0.004741-- Epoch 1\n",
      "\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 24.84, NNZs: 518, Bias: -1.000000, T: 37335, Avg. loss: 0.008785\n",
      "Total training time: 1.42 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 27.00, NNZs: 617, Bias: -1.000000, T: 37335, Avg. loss: 0.009214\n",
      "Total training time: 1.29 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 6.71, NNZs: 39, Bias: -1.000000, T: 37335, Avg. loss: 0.000857\n",
      "Norm: 10.77, NNZs: 99, Bias: -2.000000, T: 37335, Avg. loss: 0.003589Total training time: 1.28 seconds.\n",
      "Total training time: 1.27 seconds.\n",
      "\n",
      "-- Epoch 1\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.15, NNZs: 149, Bias: -1.000000, T: 37335, Avg. loss: 0.002303\n",
      "Total training time: 1.44 seconds.\n",
      "-- Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  13 | elapsed:    2.8s remaining:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 10.15, NNZs: 97, Bias: -1.000000, T: 37335, Avg. loss: 0.002973\n",
      "Total training time: 1.40 seconds.\n",
      "-- Epoch 1\n",
      "Norm: 18.63, NNZs: 305, Bias: -1.000000, T: 37335, Avg. loss: 0.005277\n",
      "Total training time: 1.28 seconds.\n",
      "Norm: 15.75, NNZs: 221, Bias: -2.000000, T: 37335, Avg. loss: 0.004071\n",
      "Total training time: 1.38 seconds.\n",
      "Norm: 13.30, NNZs: 163, Bias: -1.000000, T: 37335, Avg. loss: 0.003589\n",
      "Total training time: 1.26 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  13 | elapsed:    4.0s remaining:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 57.73, NNZs: 2645, Bias: 1.000000, T: 37335, Avg. loss: 0.045909\n",
      "Total training time: 0.88 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=5, n_iter_no_change=5, n_jobs=-1,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nNxcfBmH3O0"
   },
   "source": [
    "#### Evaluating the classification metric without the Tag 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "zwNfsKEpH464",
    "outputId": "0caac39c-821f-4579-9c95-cffe8f30c9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.69      0.36      0.47        67\n",
      "B-creative-work       0.40      0.10      0.16        41\n",
      "        B-group       0.42      0.15      0.22        68\n",
      "     B-location       0.73      0.28      0.40       165\n",
      "       B-person       0.72      0.28      0.41       186\n",
      "      B-product       0.47      0.18      0.26        38\n",
      "  I-corporation       0.00      0.00      0.00        16\n",
      "I-creative-work       0.00      0.00      0.00        53\n",
      "        I-group       0.25      0.12      0.16        51\n",
      "     I-location       0.60      0.04      0.07        83\n",
      "       I-person       0.67      0.17      0.27        93\n",
      "      I-product       0.59      0.20      0.29        51\n",
      "\n",
      "      micro avg       0.61      0.20      0.30       912\n",
      "      macro avg       0.46      0.16      0.23       912\n",
      "   weighted avg       0.57      0.20      0.28       912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_classes = classes.copy()\n",
    "new_classes.pop()\n",
    "print(classification_report(y_pred=per.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YoQBEuWIQfR"
   },
   "source": [
    "### 2.2 SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "id": "xspjV5_UIQJD",
    "outputId": "881faa8a-0d2e-4ac7-a5bd-110fdaec8a23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       1.00      0.27      0.42        67\n",
      "B-creative-work       0.00      0.00      0.00        41\n",
      "        B-group       0.00      0.00      0.00        68\n",
      "     B-location       0.86      0.04      0.07       165\n",
      "       B-person       0.83      0.10      0.18       186\n",
      "      B-product       1.00      0.05      0.10        38\n",
      "  I-corporation       0.00      0.00      0.00        16\n",
      "I-creative-work       0.00      0.00      0.00        53\n",
      "        I-group       0.00      0.00      0.00        51\n",
      "     I-location       0.00      0.00      0.00        83\n",
      "       I-person       0.83      0.05      0.10        93\n",
      "      I-product       0.00      0.00      0.00        51\n",
      "\n",
      "      micro avg       0.89      0.05      0.10       912\n",
      "      macro avg       0.38      0.04      0.07       912\n",
      "   weighted avg       0.52      0.05      0.10       912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)\n",
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIGqLmQ9IXgB"
   },
   "source": [
    "### 2.3 Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "vdEPspWIIZk_",
    "outputId": "1143ddd8-d7bd-42a0-a1c5-185b56d6d061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.90      0.39      0.54        67\n",
      "B-creative-work       0.33      0.02      0.05        41\n",
      "        B-group       0.50      0.15      0.23        68\n",
      "     B-location       0.77      0.26      0.39       165\n",
      "       B-person       0.68      0.25      0.37       186\n",
      "      B-product       0.70      0.18      0.29        38\n",
      "  I-corporation       0.00      0.00      0.00        16\n",
      "I-creative-work       0.00      0.00      0.00        53\n",
      "        I-group       0.38      0.06      0.10        51\n",
      "     I-location       0.42      0.12      0.19        83\n",
      "       I-person       0.67      0.19      0.30        93\n",
      "      I-product       0.60      0.18      0.27        51\n",
      "\n",
      "      micro avg       0.66      0.19      0.30       912\n",
      "      macro avg       0.49      0.15      0.23       912\n",
      "   weighted avg       0.59      0.19      0.29       912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)\n",
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels = new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K1jFKO-nIeFn"
   },
   "source": [
    "While the precision values are somewhat is the acceptable range, the recall values are very poor and so is their harmonic mean - F1-score. None of the above classifiers produced satisfying results. It is obvious that it is not going to be easy to classify named entities using regular classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Lv_NzyVIjF-"
   },
   "source": [
    "## 3 - Using Conditional Random Fields\n",
    "#### Conditional random fields (CRFs) are a class of statistical modeling method often applied in pattern recognition and machine learning and used for structured prediction. CRFs is often used for labeling or parsing of sequential data, such as natural language processing and CRFs find applications in POS Tagging, named entity recognition, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VILUPFn4ImaI"
   },
   "source": [
    "#### Load the data as a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REkIoN3aIdnc"
   },
   "outputs": [],
   "source": [
    "train_data_list = train_data.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKV928TqIsh6"
   },
   "source": [
    "### Perform POS tagging for every token in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "KOGC5pErIqdC",
    "outputId": "9d8110c1-3994-4d85-d40e-344710e8bba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Jxz4YRCIyli"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, doc in enumerate(train_data_list):\n",
    "    docs = [(doc[0],doc[1])]\n",
    "    tokens = [doc[0]]\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    data.append([(w, pos, label) for (w, label), (word, pos) in zip(docs, tagged)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWHqcBjvI2XU"
   },
   "source": [
    "#### How this data variable looks after POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "id": "m79m3kLZI4cy",
    "outputId": "865ac80f-85c3-4299-c64a-1c660480fa38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('@paulwalk', 'NN', 'O')],\n",
       " [('It', 'PRP', 'O')],\n",
       " [(\"'s\", 'POS', 'O')],\n",
       " [('the', 'DT', 'O')],\n",
       " [('view', 'NN', 'O')],\n",
       " [('from', 'IN', 'O')],\n",
       " [('where', 'WRB', 'O')],\n",
       " [('I', 'PRP', 'O')],\n",
       " [(\"'m\", 'VBP', 'O')],\n",
       " [('living', 'NN', 'O')]]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "la93FXPQI-Gx"
   },
   "source": [
    "### Begin training on the CRFsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "ILzTGYZNElF4",
    "outputId": "b2a3cd78-2bc0-4492-a727-d960a0ccd3b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.6)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_6Hrb1fI_jw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXn5sTkBJKdl"
   },
   "source": [
    "#### I will extract more features in the crfsuite format (word parts, simplified POS tags, lower/title/upper flags, features of nearby words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfHkprypJM6p"
   },
   "outputs": [],
   "source": [
    "def word2features(doc, i):\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "    features = [\n",
    "        'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        'word[-3:]=' + word[-3:],\n",
    "        'word[-2:]=' + word[-2:],\n",
    "        'word.isupper=%s' % word.isupper(),\n",
    "        'word.istitle=%s' % word.istitle(),\n",
    "        'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag\n",
    "    ]\n",
    "\n",
    "    # Features for words that are not\n",
    "    # at the beginning of a document\n",
    "    if i > 0:\n",
    "        word1 = doc[i-1][0]\n",
    "        postag1 = doc[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            '-1:word.istitle=%s' % word1.istitle(),\n",
    "            '-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '-1:postag=' + postag1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')  #Beginning of a sentence\n",
    "    # If we have features at the beginning of a sentence\n",
    "    if i < len(doc)-1:\n",
    "        word1 = doc[i+1][0]\n",
    "        postag1 = doc[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            '+1:word.istitle=%s' % word1.istitle(),\n",
    "            '+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:word.isdigit=%s' % word1.isdigit(),\n",
    "            '+1:postag=' + postag1\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS') #End of a sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "def extract_features(doc):\n",
    "    return [word2features(doc, i) for i in range(len(doc))]\n",
    "\n",
    "def get_labels(doc):\n",
    "    return [label for (token, postag, label) in doc]\n",
    "\n",
    "def get_tokens(doc):\n",
    "    return [token for token, postag, label in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6A-XVte9JP2r"
   },
   "outputs": [],
   "source": [
    "X = [extract_features(doc) for doc in data]\n",
    "y = [get_labels(doc) for doc in data]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVmhoJ3nJRlM"
   },
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',c1=0.1,c2=0.1,max_iterations=100,all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "HTWJAZUVJVDt",
    "outputId": "16e55a31-d0ce-4d08-969d-604b2061f374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       1.00      0.39      0.57        38\n",
      "B-creative-work       0.00      0.00      0.00        21\n",
      "        B-group       0.46      0.10      0.16        61\n",
      "     B-location       0.57      0.25      0.34       106\n",
      "       B-person       0.57      0.32      0.41       113\n",
      "      B-product       0.80      0.28      0.41        29\n",
      "  I-corporation       1.00      0.20      0.33         5\n",
      "I-creative-work       0.33      0.04      0.08        45\n",
      "        I-group       0.20      0.05      0.08        19\n",
      "     I-location       0.56      0.16      0.25        57\n",
      "       I-person       0.52      0.22      0.31        64\n",
      "      I-product       0.38      0.09      0.15        32\n",
      "\n",
      "      micro avg       0.57      0.21      0.30       590\n",
      "      macro avg       0.53      0.18      0.26       590\n",
      "   weighted avg       0.53      0.21      0.29       590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nC56xMvYJbBR"
   },
   "source": [
    "### It is evident that the F1 scores for Conditional Random Field approach is better than regular classifiers, but not good enough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSE3gG9zJfS2"
   },
   "source": [
    "## 4 - Using Deep Learning Methods\n",
    "###4.1 I will now look to improve the earlier results using LSTM based methods. The method shown below encodes character level information. The advantage of this method over an LSTM with CRF model is that I can use basically everything that produces a single vector for a sequence of characters that represent a word. In case of the latter, though it may produce failry good results, If we haven’t seen a word a prediction time, we have to encode it as unknown and have to infer it’s meaning by it’s surrounding words.\n",
    "\n",
    "\n",
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VxDhlkmMM2q5",
    "outputId": "8065891d-319a-4d27-bfbf-0f8a14ce5213"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13794"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(train_data[\"Name\"].values))\n",
    "n_words = len(words); n_words # Number of unique words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DG0Br8TSNKcS",
    "outputId": "63cf2b8e-4357-4db6-ceca-7616a1d2093f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(train_data[\"Tag\"].values)) \n",
    "n_tags = len(tags); n_tags # Number of unique tags in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7frX87GN5V6"
   },
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NzB1eqVPEZu"
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zj_PhubSnf_-"
   },
   "source": [
    "#### Now I am mapping the sentences to a number sequence and then padding the string. Remember that to use null as a padding cost, I increased the term index by one. This is done because I want to use the embedding layer mask zero parameter to disregard zero-value outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "Uv5MpjwwPE1B",
    "outputId": "fc4d27d4-4455-428a-8bff-f9267fafc993"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_word = [[word2idx[w[0]] for w in s] for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwbTc6X6PLOq"
   },
   "outputs": [],
   "source": [
    "X_word = pad_sequences(maxlen=max_len, sequences=X_word, value=word2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clcZi57MoOTZ"
   },
   "source": [
    "Now I will build a dictionary for the characters I have and then construct the character sequence for each token. Max_len for characters has been arbitrarily set as 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-bABQw5iPQ5p",
    "outputId": "3eebf2aa-134d-4b59-8997-b92d414bf669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "chars = set([w_i for w in words for w_i in w])\n",
    "n_chars = len(chars)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQl2ozrCPTJA"
   },
   "outputs": [],
   "source": [
    "char2idx = {c: i + 2 for i, c in enumerate(chars)}\n",
    "char2idx[\"UNK\"] = 1\n",
    "char2idx[\"PAD\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z9_-o6LSPWD7"
   },
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in data:\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                word_seq.append(char2idx.get(sentence[i][0][j]))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"PAD\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    X_char.append(np.array(sent_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItRpI6lpokIA"
   },
   "source": [
    "For our tag series, we must do the same mapping and padding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LK9CFPmgPZU5"
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in data]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, value=tag2idx[\"PAD\"], padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MIuFCqRPeEh"
   },
   "outputs": [],
   "source": [
    "X_word_tr, X_word_te, y_tr, y_te = train_test_split(X_word, y, test_size=0.1, random_state=2018)\n",
    "X_char_tr, X_char_te, _, _ = train_test_split(X_char, y, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g33U3u7gPhKy"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thuONDAmo8U3"
   },
   "source": [
    "The approach is to wrap the components in a TimeDistributed layer that should be added to the characters to apply the same layers to each sequence of characters. Instead of a sigmoid activation, I am using a softmax activation because categorical_crossentropy loss forces the model to distribute probability similar to a softmax. Just because, the labels are categorical, I prefer to use softmax over sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "Bs0aAnGPPjiD",
    "outputId": "6438a027-f034-4800-a949-e7dcb57aedf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# input and embedding for words\n",
    "word_in = Input(shape=(max_len,))\n",
    "emb_word = Embedding(input_dim=n_words + 2, output_dim=20,\n",
    "                     input_length=max_len, mask_zero=True)(word_in)\n",
    "\n",
    "# input and embeddings for characters\n",
    "char_in = Input(shape=(max_len, max_len_char,))\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars + 2, output_dim=10,\n",
    "                           input_length=max_len_char, mask_zero=True))(char_in)\n",
    "# character LSTM to get word encodings by characters\n",
    "char_enc = TimeDistributed(LSTM(units=20, return_sequences=False,\n",
    "                                recurrent_dropout=0.5))(emb_char)\n",
    "\n",
    "# main LSTM\n",
    "x = concatenate([emb_word, char_enc])\n",
    "x = SpatialDropout1D(0.3)(x)\n",
    "main_lstm = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                               recurrent_dropout=0.6))(x)\n",
    "out = TimeDistributed(Dense(n_tags + 1, activation=\"softmax\"))(main_lstm)\n",
    "\n",
    "model = Model([word_in, char_in], out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "id": "fgooe4PYPlwi",
    "outputId": "d54fa07f-969e-44c6-f4d9-051bada6fc6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 75, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 75, 10, 10)   960         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 75, 20)       275920      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 75, 20)       2480        time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 75, 40)       0           embedding_1[0][0]                \n",
      "                                                                 time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 75, 40)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 75, 100)      36400       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 75, 14)       1414        bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 317,174\n",
      "Trainable params: 317,174\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "zBgT8IPIPq9m",
    "outputId": "1c1eaee2-13c7-40a7-bd73-6a9a3a61c253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 45136 samples, validate on 5016 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "45136/45136 [==============================] - 70s 2ms/step - loss: 0.9892 - acc: 0.9397 - val_loss: 0.3051 - val_acc: 0.9502\n",
      "Epoch 2/5\n",
      "45136/45136 [==============================] - 67s 1ms/step - loss: 0.2664 - acc: 0.9505 - val_loss: 0.2594 - val_acc: 0.9502\n",
      "Epoch 3/5\n",
      "45136/45136 [==============================] - 67s 1ms/step - loss: 0.2178 - acc: 0.9505 - val_loss: 0.2448 - val_acc: 0.9502\n",
      "Epoch 4/5\n",
      "45136/45136 [==============================] - 67s 1ms/step - loss: 0.1768 - acc: 0.9521 - val_loss: 0.2491 - val_acc: 0.9504\n",
      "Epoch 5/5\n",
      "45136/45136 [==============================] - 67s 1ms/step - loss: 0.1552 - acc: 0.9575 - val_loss: 0.2600 - val_acc: 0.9504\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_word_tr,\n",
    "                     np.array(X_char_tr).reshape((len(X_char_tr), max_len, max_len_char))],\n",
    "                    np.array(y_tr).reshape(len(y_tr), max_len, 1),\n",
    "                    batch_size=256, epochs=5, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhbD6HEdPt1F"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict([X_word_te,np.array(X_char_te).reshape((len(X_char_te),max_len, max_len_char))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0sabf_Gp1BT"
   },
   "source": [
    "Accuracy of this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S1Mz_9CutrRq",
    "outputId": "cab0e0da-24aa-4580-8ac1-9784ca51eba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9542436748609366\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "  p = np.argmax(y_pred[i], axis=-1)\n",
    "  for w, t, pred in zip(X_word_te[i], y_te[i], p):\n",
    "      if w != 0:\n",
    "        if idx2tag[t]==idx2tag[pred]:\n",
    "          count+=1\n",
    "\n",
    "print(\"Accuracy is \",count/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s3L1d9XjsAND"
   },
   "source": [
    "While this accuracy is very good, we can achieve SOTA using ELMO embeddings. The next section discusses the code and procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9w-H1yV-Mw-L"
   },
   "source": [
    "##4.2 - Using ELMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvryrrN4qKWI"
   },
   "source": [
    "ELMo embeddings are embeddings from a language model trained on the 1 Billion Word Benchmark. Unlike most widely used word embeddings, ELMo word representations are functions of the entire input sentence. They are computed on top of two-layer bidirectional language model with character convolutions, as a linear function of the internal network states. Exisiting literature has shown remarkable performance by ELMO elmbeddings compared to other context aware embeddings. Hence, I am using this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtWmYr2kMyaR"
   },
   "outputs": [],
   "source": [
    "max_len = 2\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PByhtZHqh0d"
   },
   "source": [
    "For the use of neural nets we need to use equal-length input sequences. So I am going to pad my sentences to a length of 2. But first I need a dictionary of tags to map my labels to numbers. I could have padded with a length of 2 or 50, it simply does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aITl4krLM4Zf",
    "outputId": "15229e25-255f-4700-8a3f-dd6dfe6375fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@paulwalk'], ['It'], [\"'s\"], ['the']]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[w[0] for w in s] for s in data]\n",
    "X[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SETYPLs2sVz9"
   },
   "source": [
    "This is how a padded sequence will look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "VG7hQVoBNDIh",
    "outputId": "4ff96151-a081-4dc5-fad5-d223f6b6fcde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@paulwalk', '__PAD__'],\n",
       " ['It', '__PAD__'],\n",
       " [\"'s\", '__PAD__'],\n",
       " ['the', '__PAD__']]"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = []\n",
    "for seq in X:\n",
    "    new_seq = []\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[i])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_X.append(new_seq)\n",
    "X = new_X\n",
    "X[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gT9aIDEmNHOh"
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in data]  # Repeat above process for the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g4tSDny5NS-K"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CcrD6VWdNWQH",
    "outputId": "fb155e37-59f0-4a82-b24c-b4af09b3baa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pePUW0FQNXn-"
   },
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84NX41u7Na9K"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GV93JtgdskGP"
   },
   "source": [
    "### Initializing the ELMO embeddings from tensorflow hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nEHasNFNdKT"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZYQlwKLNeuw"
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QOfYQgDNgvn"
   },
   "outputs": [],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahmpLhSrsth-"
   },
   "source": [
    "The below function takes a sequence of strings and returns a sequence of 1024-dimensional vectors of the ELMo embedding. I will later use this function with the Lambda layer of keras to get the embedding sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wFhgfqUNivH"
   },
   "outputs": [],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x, tf.string)),\"sequence_len\": tf.constant(batch_size*[max_len])},signature=\"tokens\",as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-9MuKhANpd4"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4AjS7ZGQNrRi",
    "outputId": "aea28d2b-5ac3-4da4-fccd-52369de29fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
    "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                       recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
    "x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
    "                           recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "x = add([x, x_rnn])  # residual connection to the first biLSTM\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eykizVTHNtfl"
   },
   "outputs": [],
   "source": [
    "model = Model(input_text, out)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpYJMP7gtK8O"
   },
   "source": [
    "I made the number of samples divisible by the batch_size to make it work. For some reason, I couldn't generalize it. You will find the same issue is when I test the model with the \"test.txt\" file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uh7wwV4wOibq"
   },
   "outputs": [],
   "source": [
    "X_tr, X_val = X_tr[:1213*batch_size], X_tr[-135*batch_size:]\n",
    "y_tr, y_val = y_tr[:1213*batch_size], y_tr[-135*batch_size:]\n",
    "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)\n",
    "y_val = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "rojwtUf3OjQq",
    "outputId": "b3fa2370-7088-4daf-f689-6341e575deb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38816 samples, validate on 4320 samples\n",
      "Epoch 1/4\n",
      "38816/38816 [==============================] - 58s 1ms/step - loss: 0.0970 - acc: 0.9790 - val_loss: 0.0904 - val_acc: 0.9797\n",
      "Epoch 2/4\n",
      "38816/38816 [==============================] - 52s 1ms/step - loss: 0.0753 - acc: 0.9820 - val_loss: 0.0886 - val_acc: 0.9801\n",
      "Epoch 3/4\n",
      "38816/38816 [==============================] - 52s 1ms/step - loss: 0.0649 - acc: 0.9835 - val_loss: 0.0918 - val_acc: 0.9802\n",
      "Epoch 4/4\n",
      "38816/38816 [==============================] - 52s 1ms/step - loss: 0.0553 - acc: 0.9848 - val_loss: 0.0970 - val_acc: 0.9802\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(X_tr), y_tr, validation_data=(np.array(X_val), y_val),\n",
    "                    batch_size=batch_size, epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DSVVTILtcKp"
   },
   "source": [
    "### It is pretty evident that this model produces the best result out of the lot. As a reult, I will generate the submission file using this residual LSTM network with ELMO  embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Msm7tDAottoZ"
   },
   "source": [
    "A preview of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "hnKIKJ-zQcv8",
    "outputId": "1e8a1311-5cd5-45e6-b96b-4dfaafed19b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Predicted_label True_label\n",
      "=============================================\n",
      "more                 O               O\n",
      "=============================================\n",
      "buy                  O               O\n",
      "=============================================\n",
      "and                  O               O\n",
      "=============================================\n",
      "had                  O               O\n"
     ]
    }
   ],
   "source": [
    "print(\"{:15} {:10} {}\".format(\"Word\", \"Predicted_label\", \"True_label\"))\n",
    "for i in range(4):\n",
    "  p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
    "  p = np.argmax(p, axis=-1)\n",
    "\n",
    "  print(\"=\"*45)\n",
    "  for w, true, pred in zip(X_te[i], y_te[i], p):\n",
    "      if w != \"__PAD__\":\n",
    "          print(\"{:20} {:15} {}\".format(w, tags[pred], tags[true]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Of_QNYJ1RMug"
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "X_te.extend([[\"__PAD__\"]]*(2*batch_size))\n",
    "for i in range(len(X_te)):\n",
    "  try:\n",
    "    p = model.predict(np.array(X_te[i:i+batch_size]))[0]\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, true, pred in zip(X_te[i], y_te[i], p):\n",
    "        if w != \"__PAD__\":\n",
    "          if true==pred:\n",
    "            count+=1\n",
    "  except:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igSs-YdYT49d"
   },
   "source": [
    "### The test accuracy for the model is highest of all the methods I implemented so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BQ93Rta2SYmZ",
    "outputId": "b72ff11f-ea1b-49f9-a777-efd49323ebb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.9562174771218375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is \",count/(len(X_te)-(2*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXELhKTktxJP"
   },
   "source": [
    "# Import the test data and pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "K0BXiDxXQhBM",
    "outputId": "10758482-ca3e-4a4e-8e3a-34ebcb6391b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['&'], ['gt'], [';']]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "test_data = pd.read_csv(\"test.txt\", sep=\"\\t\", header=None,names=[\"Name\"],quoting=csv.QUOTE_NONE,encoding='utf-8')\n",
    "test_data = test_data.dropna()\n",
    "test_data_list = test_data.values.tolist()\n",
    "test_data_list.extend([[\"__PAD__\"]]*(2*batch_size))\n",
    "test_data_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IgaL6hOORwBt"
   },
   "outputs": [],
   "source": [
    "new_test_X = []\n",
    "for seq in test_data_list:\n",
    "    new_seq = []\n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            new_seq.append(seq[i])\n",
    "        except:\n",
    "            new_seq.append(\"__PAD__\")\n",
    "    new_test_X.append(new_seq)\n",
    "test_X = new_test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YeYneOqt5Xx"
   },
   "source": [
    "After padding, the test sequence will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Veg0aFTjSTN6",
    "outputId": "b3a5c722-796f-4b05-c5fc-e0a1b4640176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['&', '__PAD__'], ['gt', '__PAD__'], [';', '__PAD__'], ['*', '__PAD__']]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7VOy_6Jt-GR"
   },
   "source": [
    "Preview the test predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "ZW6a7QsIR58m",
    "outputId": "3ba6fc8b-1d55-4f58-f922-b0a9993334bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            Predicted Labels\n",
      "========================================\n",
      "&                        O     \n",
      "========================================\n",
      "gt                       O     \n",
      "========================================\n",
      ";                        O     \n"
     ]
    }
   ],
   "source": [
    "print(\"{:15} {:5}\".format(\"Word\", \"Predicted Labels\"))\n",
    "for i in range(3):\n",
    "  p = model.predict(np.array(test_X[i:i+batch_size]))[0]\n",
    "  p = np.argmax(p, axis=-1)\n",
    "\n",
    "  print(\"=\"*40)\n",
    "  for w,pred in zip(test_X[i], p):\n",
    "      if w != \"__PAD__\":\n",
    "          print(\"{:25}{:5} \".format(w, tags[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zA5kkeXbwE88"
   },
   "source": [
    "I encountered the end batch error as I had mentioned before. I am terminating this code block using try and except block. However, all the predictions are successfully made and appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "5PDYzG3ESQwN",
    "outputId": "ab47c32c-d84b-409e-ef79-0fc49e5a4dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "predictions = []\n",
    "count = 0\n",
    "for i in range(len(test_X)):\n",
    "  try:\n",
    "    p = model.predict(np.array(test_X[i:i+batch_size]))[0]\n",
    "    p = np.argmax(p, axis=-1)\n",
    "\n",
    "    for w,pred in zip(test_X[i], p):\n",
    "        if w != \"__PAD__\":\n",
    "          predictions.append(tags[pred])\n",
    "          print('count = ', count, end='\\r')\n",
    "    count+=1\n",
    "  except:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXRIcVT3Zs8q"
   },
   "source": [
    "# 5. Bonus Question -  Generating confidence score for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFZVNz86Zaot"
   },
   "outputs": [],
   "source": [
    "conf_score = []\n",
    "count = 0\n",
    "for i in range(len(test_X)):\n",
    "  try:\n",
    "    p = model.predict(np.array(test_X[i:i+batch_size]))[0]\n",
    "    p = np.max(p, axis=-1)[0]\n",
    "    conf_score.append(p)\n",
    "  except:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ9mfg0OwmmV"
   },
   "source": [
    "## Create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "gSNP4Q4UX3jx",
    "outputId": "77e5d0fa-1c03-48cf-c47c-06c14f367899"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23388</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>0.995202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>this</td>\n",
       "      <td>O</td>\n",
       "      <td>0.999267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23390</th>\n",
       "      <td>dress</td>\n",
       "      <td>O</td>\n",
       "      <td>0.999869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23391</th>\n",
       "      <td>code</td>\n",
       "      <td>O</td>\n",
       "      <td>0.953659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23392</th>\n",
       "      <td>😂</td>\n",
       "      <td>O</td>\n",
       "      <td>0.971562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Predicted Tag  Confidence Score\n",
       "23388   with             O          0.995202\n",
       "23389   this             O          0.999267\n",
       "23390  dress             O          0.999869\n",
       "23391   code             O          0.953659\n",
       "23392      😂             O          0.971562"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data = pd.DataFrame(\n",
    "          {'Name': test_data_list[:23393],\n",
    "           'Predicted Tag': predictions[:23393],\n",
    "           'Confidence Score': conf_score[:23393]\n",
    "    })\n",
    "\n",
    "sub_data['Name'] = sub_data['Name'].str[0]\n",
    "sub_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Nv7GWyykbjQ"
   },
   "outputs": [],
   "source": [
    "sub_data.to_csv(\"submisison.txt\", sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ArD-kUfZKO4u",
    "outputId": "59d3cf81-fb02-4369-c434-05981b1b269d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission saved\n"
     ]
    }
   ],
   "source": [
    "print(\"submission saved\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Infrrd Coding Challenge.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
